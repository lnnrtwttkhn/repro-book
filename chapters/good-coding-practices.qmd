---
editor: source
engine: knitr
execute:
  eval: false
  warning: false
  message: false
code-annotations: hover
---

```{r setup}
#| echo: false
library(tibble)
library(dplyr)
library(tidyr)
library(assertr)
```

# Good coding practices

In the last chapters, you have learned how to name your names and variables and how to set up a decent project structure.
In this chapter, you will learn good coding practices to help other researchers and future you with the code you used for your analysis.

## Respective R projects

As a researcher (and as a student) you work on different projects simultaneously.
You have different research projects and teaching parts that you need to cover in your job.
You attend different courses and do presentations and data analyses in these seminars and lectures.
As you have learned in the previous chapter about project structure, it makes sense to set up your files and folders in a particular research project folder.

```
|projects
|--version-control-book
|--reproducibility-book
|--grant_neuroscience_horizon
|--grant_neuroscience_dfg
```

We highly recommend to use specific R-projects for each project, respectively.
This will become clear throughout this chapter and the next chapter about `renv`.

To create an R-project, follow these steps:

1. Open RStudio
1. Click on the blue {{< fa cube >}} cube with a R in it and a green plus {{< fa circle-plus >}} on the outside.
1. Decide whether you want to create a new directory or an existing directory.

Depending on your situation it makes sense to either create a new directory or turn an existing folder into an R-project.
When you are at the beginning of your project and have not set up a project structure yet, it makes sense to create a new directory.
Make sure, that in this case, your directory name aligns well with your project.
When you have already set up a project structure, it makes sense to turn your project folder into an R-project. Make sure that in this case your project folder is the folder you turn into an R-project.

::: panel-tabset
## New Directory

Click on **New Directory**, then **New Project** and type in your directory name. 
Make sure that your project is at the correct place in your folder system.
At this time point, it does not matter whether you want to create a *git repository* and/or use *renv* with this project.
In the future chapters you will learn the advantages of using git and renv.

When you click on **Create project**, your R project will be created.
You will see that R created a folder named after your directory and that one file `directory-name.Rproj` is in this folder.

## Existing Directory

Click on **Existing Directory** and make sure which folder you want to turn into an R-project.

When you click on **Create project**, your R-project will be created. You will see that R put a file in your chosen folder called `directory-name.Rproj`.
:::

::: callout-tip
## What is an `.Rproj`-file?

The `.Rproj`-file contains the settings for all files related to your specific R project.
It is automatically created when you create an R-project. By double-clicking on the file, you open the project in RStudio. It is not recommended to change this file manually.
:::

After you have created your R project it is time to take a deep look into your R-scripts containing the code for your projects.

## Comments

Comments are probably the most important part of your scripts.
Whenever you write a `#` in your R-script, all code after that `#` will be identified as comment and therefore not be executed as code.
Thus, if you put a `#` at the beginning of a line, the whole line will be identified as comment.
Here are some thoughts about comments by Nicola Rennie:

::: callout-note
## Adding comments

- Add comments using a `#` in R (in a separate line)
- Comments don`t need to explain *what* your code does
- Comments should explain *why* you did it
:::

You can use `#` not only for comments but also for creating sections and subsections in your R-script.
To do so, you must start a line with at least one hash `#` and put at least 4 hyphens after your comment.
The number of hashes you use at the beginning determines the level of section.

```{r filename = "Code"}
# Section 1 ----

## Subsection 1.1 ----

## Sebsection 1.2 ----

# Section 2 ----
```

## Absolute and relative file paths

All of the time when you are doing research, you have to conduct your analysis on some sort of data.
This data is usually stored in one or more files.
Thus, you have to read the data into your script.
To do so, you need to refer to the files you want to read.
Here comes a first advantage of setting up a particular R-project for your research project.

You can read data or code into your R-environment by referring to your data through absolute paths and relative paths.

### Absolute file paths

Using an absolute path means that you refer to your file name by going through your whole computer folder structure:

```{r filename = "Code"}
#| eval: false
data <- read_csv("/Users/my-user-name/document/projects/my-project/data/data-raw.csv")
```

Using absolute file paths is not recommended in terms of computational reproducibility.
A collaborator or interested researcher who downloaded your scripts and wants to reproduce your analysis has to change these paths before the scripts can run correctly.

```{r filename = "Code"}
#| eval: false
data <- read_csv("/Users/user-name-b/desktop/work/research/my-project/data/data-raw.csv")
```

### Relative file paths

A relative file path takes the path from your current *working directory* and puts it before your relative path.
You can check your current working directory in R by using the `getwd()` command in the R Console.

```{zsh, filename="Console"}
>getwd()
[1] "Users/my-user-name/my-project"
```

By default, the working directory in an R project is the project folder, in the example called `my-project`.

You can then use the relative file path from that folder to read your data.
You can use the file path that starts *after* the working directory:

```{r filename = "Code"}
#| eval: false
data <- read_csv("data/data-raw.csv")
```

Thus, all relative paths to the files in an R-project remain the same insensitive to the person who wants to work with that project.

## Code Style {#sec-codestyle}

>"Good coding style is like correct punctuation: you can manage without it, butitsuremakethingseasiertoread" 
> -- Wickham et al. (2023)

One important aspect that fosters understandability of code is the code style.
In this section, we will present the `tidyverse`-codestyle [@wickham2023].
The Tidyverse is a collection of R packages particularly useful for data wrangling, manipulation and visualization.
All packages share an underlying design philosophy, grammar, and data structures.

In psychology, the grammar of tidyverse is widely used for data wrangling.
In this section, we will give a short introduction on code style.

### Names

Not only files and folders should be named well, the same applies to variable names and functions in scripts.
Variable and function names should only consist of lowercase letters, numbers and underscores `_`.
It is better to have descriptive long names rather than short abbreviations you do not understand in the future.

```{r filename = "Code"}
#| eval: false
# Strive for:
short_flights <- flights |> filter(air_time < 60)

# Avoid:
SHORTFLIGHTS <- flights |> filter(air_time < 60)
```

### Spaces

Put spaces around mathematical operators (except `^`) and around the assignment operator (`<-`).
Do not put spaces around parentheses when you use functions.
Put a space after a comma as you would in standard English.

```{r filename = "Code"}
#| eval: false
# Strive for
mean(x, na.rm = TRUE)

# Avoid
mean (x ,na.rm=TRUE)
```

### Pipes

The pipe (either `|>`or `%>%`) is a useful operator to connect subsequent operations with your code.
The pipe takes everything left to the pipe and uses it as first argument to the function of the right side.

>Here a cartoon illustrating how the pipe works would be fun.

```{r filename = "Code"}
#| eval: false
# Without pipe
sum(c(1:4))

# With pipe
c(1:4) |> sum()
```

The pipe is particularly useful, when you subsequently connect many functions after each other. Therefore, use `|>` at the end of a line and use a space before it. The complete sequence of functions connected by a pipe is also called a **pipeline**.

```{r filename = "Code"}
#| eval: false
# Without pipe
summarise(group_by(filter(select(data, N, gender), gender == "male" | gender == "female"), gender), mean = mean(N))

# With pipe
data |>
  select(N, gender) |>
  filter(gender == "male" | gender == "female") |>
  group_by(gender) |>
  summarise(
    mean = mean(N),
    median = md(N)
  )
```

The code displayed above is way easier to read and understand for future you and other researchers, therefore increasing the possibility for reproducibility.
Translated into plain English the pipe represents an *"and then"*:

1. Take the data *and then*
1. select the variables `N` and `gender` *and then*
1. filter all observations where the variable `gender` either contains the value `male` or `female` *and then*
1. group the dataset by the variable `gender` *and then*
1. summarise your datasets by calculating the mean and median for the variable `N` for each group.


::: {.callout-note collapse="true"}
## Difference between `%>%` and `|>`

In basic code, `%>%` and `|>` behave the same in the simple cases we cover here.
In general, `%>%` has some advantages when you want to code more complex cases.
If you are interested when it matters if you either use `%>%`or `|>`, we recommend [this](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) resource.

::: panel-tabset
## `%>%`

The `%>%` pipe was introduced in the context of the `tidyverse`.
It comes with the package `magrittr` and con only be used when this package is installed and loaded.

```{r filename = "Code"}
#| eval: false
install.packages("magrittr")
library(magrittr)
```

However, you can also use it, when you load another package from the `tidyverse` such as `dplyr`. 
This is because `dplyr` imports `magrittr` when it is loaded.

## `|>`

The `|>` pipe comes with the basic R. 
To use `|>` in R, you have to go to **Tools** > **Global Options** > **Code** and tick the box **Use native pipe operator, |> (repquires R 4.1+)**.

:::

:::

### Line breaks

If a function requires you to name arguments (as `summarise()`), put each argument on a new line.
If a function does not require you to name arguments (as `group_by()`), keep your code in one line except it extends one code line.
Then, you should put each argument on its own line.

When you start a new line after using `|>` or a function as `summarise()`, indent the new line by two spaces (if not already done automatically).
If you are putting each argument on a separate line, also indent the new line by two spaces.
Make sure that the closing parenthesis `)` is on its own line and not indented.
Thus, the closing parenthesis matches the horizontal position of the function you are using.

```{r filename = "Code"}
#| eval: false
# Strive for 
flights |>  
  group_by(tailnum) |> 
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

# Avoid
flights|>
  group_by(tailnum) |> 
  summarize(
             delay = mean(arr_delay, na.rm = TRUE), 
             n = n()
           )

# Avoid
flights|>
  group_by(tailnum) |> 
  summarize(
  delay = mean(arr_delay, na.rm = TRUE), 
  n = n()
  )
```

## Tidy Data

```{r}
#| results: asis
#| eval: true
#| echo: false
cat(make_figure("horst-tidydata"))
```

When you work with datasets, you will likely not be able to directly conduct your data analysis (e.g. `t-tests`, `ANOVAs`, `GLMs`).
In fact, most of the time you are facing datasets, on which you will spend more time organizing your data than running your analysis.
A helpful concept is **tidy data**, which is a common guideline for datasets to be organized.
Tidy data refers to the `tidyverse` that was introduced in @sec-codestyle.
Following tidy data guidelines will help you running analyses and getting the most out of your data.

::: callout-important
## Tidy Data

Tidy datasets follow three basic rules:

1.  Each variable is a column; each column is a variable.
1.  Each observation is a row; each row is an observation.
1.  Each value is a cell; each cell is a value.
:::

```{r}
#| results: asis
#| eval: true
#| echo: false
cat(make_figure("tidy-data"))
```

The way from raw to tidy data can be long and frustrating.
This book cannot provide a full insight into data wrangling and data manipulation.
However, if you are interested in learning functions for data manipulation, we recommend studying the `dplyr()`-package and its [documentation](https://dplyr.tidyverse.org) as well as the `tidyr()`-package and its [documentation](https://tidyr.tidyverse.org).
From our experience, using and sharing code written in the tidyverse language fosters understanding of the code, therefore enhancing computational reproducibility.

### Data structures

Data can be structured in different ways. When your data is tidy, you still can face **wide** or **long data**.

As a rule of thumb, you can memorise this:
Data that is structured in a *long format* usually contains *repetitive* values in the first column of the dataset.
Data that is structured in a *wide format* usually contains *non-repetitive* values in the first column of the dataset.

::: panel-tabset

## {{< fa arrows-left-right >}} Wide format

```{r filename = "Code"}
#| echo: false
#| eval: true

#load library
library(tibble)

#set up data frame
data_wide <- tibble(
  participant = 1:3,
  congruent = c(560, 623, 547),
  incongruent = c(720, 799, 812)
)

print(data_wide)
```

## {{< fa arrows-up-down >}} Long format

```{r filename = "Code"}
#| echo: false
#| eval: true
data_long <- tibble(
  participant = c(1,1,2,2,3,3),
  congruency = rep(c("congruent", "incongruent"), times = 3),
  reaction_time = c(560,720, 623, 799, 547, 812)
)

print(data_long)
```

:::

However, this rule of thumb does not always apply, for example when data is rearranged.

```{r filename = "Code"}
#| echo: false
#| eval: true

print("Data in long format")
data_long |>
  select(reaction_time, congruency, participant) |>
  print()
```

Another perspective on wide vs. long data includes the context of the data.
In research, a common question is how a variable A influences variable B.
B is dependent on A.
That makes variable B the dependent variable (DV) and variable A the independent variable (IV).
In the wide data format, the names of the factor levels of the IV are usually column names, whereas the DV is displayed in the values across these cells.
In contrast, in the long data format, the names of the factor levels of the IV are usually values in the column of the IV.
The name of the IV constitutes the column name rather than the level of the IV.
Simultaneously, the DV is displayed in one column with the name of the DV as column name and values in only this particular column.

### Changing the data structure

Dependent on which R-functions you want to use or other reasons, you might have to or want to change your data structure from wide to long or vice versa.
An easy way to do so, is to use `pivot_wider()` and `pivot_longer()` from the `tidyr()`-package.

#### `pivot_longer()`

`pivot_longer()` takes your dataset and makes it longer. 
It takes certain columns and puts their names as values into a new column.
Further, it takes the values of these columns and puts the values together in one column.


```{r filename = "Code"}
#| eval: true
library(tidyr)

data_wide |>                                # <1>
  pivot_longer(                             # <2>
    cols = c("congruent", "incongruent"),   # <3>
    names_to = "congruency",                # <4>
    values_to = "reaction_time"             # <5>
  ) |>
  print()
```

1. take the dataset `data_wide`, and then
2. apply the function `pivot_longer()` on the data by
3. specifying the columns that should be turned in to a long format,
4. naming the new column with the previous column names in it, and
5. naming the new column with the values of the previous columns in it.

#### `pivot_wider()`

`pivot_wider()` takes your dataset and makes it wider.
It takes the names of a certain column and changes them to new column names.
Further, it takes the values of a second column and puts them accross the new columns to their corresponding names.

```{r filename = "Code"}
#| eval: true

data_long |>                                # <1>
  pivot_wider(                              # <2>
    names_from = "congruency",              # <3>
    values_from = "reaction_time"           # <4>
  ) |>
  print()
```

1. take the dataset `data_long`
2. apply the function `pivot_wider` on the data by
3. specifying the column name from which to take the new column names, and
4. specifying the column namen from which to take the values of the new column names.

## Advanced: Defensive programming

Whenever you write code for data analysis or anything else, it is useful to validate what you are doing.
This is also called **defensive programming**.
Defensive in this context is meant as cautious.
Here are some potential benefits of validating your code:

- early error detection
- code clarity
- protection against invalid input
- monitor data quality
- improved documentation
- improved error handling


### The `assertr` package and it's function `verify()`

The [`assertr`](https://cran.r-project.org/web/packages/assertr/vignettes/assertr.html)-package helps you when you start considering to test your code.
When you start adopting coding in the tidyverse-codestyle, the function `verify()` will be very easy for you to apply in your code.
`verify()` can be easily integrated into a pipeline of code.
Here is an example of how verify() can be integrated into your tidy code:

```{r filename = "Code"}
#| eval: true
library(assertr)

# verify if reaction time is longer than 200ms
data_long |>
  verify(reaction_time > 200) |>
  print()
```

The `verify()` function takes a data frame (which is the first argument of the function and provided by the `|>` operator) and a logical expression.
Then, the expression is evaluated in the context of the data frame.
When the expression is `TRUE`, no error occurs and the pipe goes on.
When the expression is `FALSE`, verify will raise an error that terminates any further processing of the pipeline [@fischetti2023] (Fischetti, 2023).

```{zsh filename = "Console"}
>data_long |>
  +verify(reaction_time < 200) |>
  +print()
verification [reaction_time < 200] failed! (6 failures)

    verb redux_fn           predicate column index value
1 verify       NA reaction_time < 200     NA     1    NA
2 verify       NA reaction_time < 200     NA     2    NA
3 verify       NA reaction_time < 200     NA     3    NA
4 verify       NA reaction_time < 200     NA     4    NA
5 verify       NA reaction_time < 200     NA     5    NA
6 verify       NA reaction_time < 200     NA     6    NA

Error: assertr stopped execution
```

### Further functions and packages

The `verify()` function provides an easy way of starting validating your code within a tidyverse codestyle.
However, more functions from the `assertr`-package can be applied for defensive programming.
Going through all of these functions exceeds the scope of this book.
Therefore, we cannot only recommend to read the bycoming [vignette ](https://cran.r-project.org/web/packages/assertr/vignettes/assertr.html) by Tony Fischetti, the author of the `assertr`-package.

Furthermore, `assertr` is not the only {{< fa brands r-project >}} package dealing with defensive programming.
[`assert`](https://cran.r-project.org/web/packages/assert/assert.pdf), [`assertthat`](https://cran.r-project.org/web/packages/assertthat/assertthat.pdf), and [`testthat`](https://cran.r-project.org/web/packages/testthat/testthat.pdf) are other powerful packages in this context.
In general, code validation is not too popular in scientific practice.
It is rather prevalent in software development contexts validating functions and whole scripts for specific purposes.
These thorough testing processes extends the scope of computational reproducibility in our opinion.
Thus, we recommend `assertr::verify()` as a good starting point for defensive programming in the context of computational reproducibility.


## Acknowledgements & further reading

We would like to express our gratitude to the following resources, which have been essential in shaping this chapter.
We recommend these references for further reading:

| Resources |
|------------------------------------------------------------------------|
| Buhr, J. (2023). *Introduction to Data Analysis with R.* <https://jmbuhr.de/dataintro/> |
| Rennie, N. (2024). *Writing Better R Code.* <https://nrennie.rbind.io/training-better-r-code/> |
| Wickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). *R for Data Science (2e)*. <https://r4ds.hadley.nz> |