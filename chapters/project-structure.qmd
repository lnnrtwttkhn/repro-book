---
title: "Project Structure"
editor: 
  source:
    markdown:
      wrap: sentence
abstract: |
  In this chapter, you will explore various types of project structures.
  You will learn what elements are essential for a project structure and what key factors to consider.
  Additionally, you will gain insight into how to create a project structure for your own work and understand what should be included in a published reproducibility archive.
engine: knitr
execute:
  eval: false
---

::: {.callout-tip appearance="minimal"}
<h5>Learning Objectives</h5>

:bulb: You have explored various types of project structures.<br>
:bulb: You know the key components of a project structure.<br>
:bulb: You can evaluate the advantages and disadvantages of different project structures.<br>
:bulb: You are aware of the challenges and opportunities in creating an effective project structure.<br>
:bulb: You understand the perspective on research as either a sequential or circular process.
:::

Project structure addresses how the files and folder of your research project are structured.
This is what this chapter is about.
Other topics related to the term, such as setting a timeline for your project, will be neglected as this would lead to losing the focus on reproducibility.
A good folder structure saves you and other researchers a lot of time when revisiting or trying to understand your data.
However, there is no universal *best practice standard* for project structures.
Below are several examples of different project structures:

## Examples {#examples}

::: panel-tabset
## The Turing Way

```{zsh filename="Output"}
├── LICENSE
├── README.md # <1>
├── CODE_OF_CONDUCT.md <- Guidelines for users and contributors of the project.
├── CONTRIBUTING.md    <- Information on how to contribute to the project.
├── data
│   ├── processed      <- The final, canonical data sets for modeling.
│   └── raw            <- The original, immutable data dump.
│
├── docs               <- A default Sphinx project; see sphinx-doc.org for details
│
├── models             <- Trained and serialized models, model predictions, or model summaries
│
├── notebooks          <- Jupyter notebooks. The naming convention is a number (for ordering),
│                         the creator's initials, and a short `-` delimited description, e.g.
│                         `1.0-jqp-initial-data-exploration`.
│
├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
│   └── figures        <- Generated graphics and figures to be used in reporting
│
├── project_management <- Meeting notes and other project planning resources
│
├── src                <- Source code for use in this project.
│   │
│   ├── data           <- Scripts to download or generate data
│   │   └── make_dataset.py
│   │
│   ├── models         <- Scripts to train models and then use trained models to make
│   │   │                 predictions
│   │   ├── predict_model.py
│   │   └── train_model.py
│   │
│   └── visualisation  <- Scripts to create exploratory and results-oriented visualisations
│       └── visualise.py
└──
```

1.  The top-level README for users of this project.

Repository Structure Template by [The Turing Way](https://book.the-turing-way.org/index.html).
Used under the [LICENSE CC-BY 4.0](https://github.com/the-turing-way/reproducible-project-template/blob/main/LICENSE.md).
Reused without any modifications.

## Heidi Seibold

```         
.
├── README.md
├── analysis            <- all things data analysis
│   └── src             <- functions and other source files
├── comm
│   ├── internal_comm   <- internal communication such as meeting notes
│   └── journal_comm    <- communication with the journal, e.g. peer review
├── data
│   ├── data_clean      <- clean version of the data
│   └── data_raw        <- raw data (don't touch)
├── dissemination
│   ├── manuscripts
│   ├── posters
│   └── presentations
├── documentation       <- documentation, e.g. data management plan
└── misc                <- miscellaneous files that don't fit elsewhere
```

Research Project Template by [Heidi Seibold](https://heidiseibold.com).
No license use specified.
For source code, see [here](https://github.com/HeidiSeibold/research-project-template).
Reused without modifications.

## analysistemplates

```         
|-- 01_Data
|   |-- 01_Raw
|   `-- 02_Clean
|-- 02_Analysis
|   |-- 01_Scripts
|   |-- 02_Results
|   |-- 03_Figures
|   `-- 04_Tables
|-- 03_Manuscript
|   |-- 01_Text
|   `-- 02_Final_figures
|-- 04_Presentation
|-- 05_Misc
|-- 06_Analysis_for_publication <-- optional
|   |-- 01_Scripts              <-- optional
|   |-- 02_Results              <-- optional
|   |-- 03_Figures              <-- optional
|   `-- 04_Tables               <-- optional
|-- README.md
|-- .gitignore                  <-- optional
|-- renv                        <-- optional
```

analysis template packages by [Jonas Hagenbeck](https://github.com/jonas-hag).
Used under the [MIT License](https://github.com/jonas-hag/analysistemplates/blob/0d76d5364c231a4710d227c8a935532c137383a2/LICENSE.md#L4).
Reused without any modifications.

## WORCS

| File          | Description                     | Usage           |
|:--------------|:--------------------------------|:----------------|
| \_pkgdown.yml | YAML for package website        | do not edit     |
| DESCRIPTION   | R-package DESCRIPTION           | do not edit     |
| LICENSE.md    | Project license                 | do not edit     |
| NAMESPACE     | R-package namespace             | machine-written |
| README.md     | Read this file to get started!  | do not edit     |
| README.Rmd    | R-markdown source for readme.md | human editable  |
| worcs.Rproj   | RStudio project file            | do not edit     |
| docs/         | Package website                 | machine-written |
| inst/         | RStudio project template files  | human editable  |
| man/          | R-package documentation         | do not edit     |
| paper/        | WORCS paper source files        | human editable  |
| R/            | R-package source code           | human editable  |
| vignettes/    | R-package vignettes             | human editable  |

WORCS project structure by Van Lissa et al. ([2021](https://cjvanlissa.github.io/worcs/index.html#repository-structure)).
Used under the [GNU General Public License](https://fsf.org/).
No changes were made.
:::

::: callout-caution
## Exercise: Take on different perspectives

Pause for a moment after investigating the different project structures.
Take the perspective of a researcher that is currently working in this project structure.
How would you feel working with this structure?
What helps you, hinders you to work productively and reproducible?
Then change your perspective.
Imagine you are a researcher aiming to reproduce the results of a different research project that uses such project structures.
What would you need to reproduce analysis and results?
:::

When looking at the different project structures, it becomes clear that there is no perfect or correct project structure for a research project.
The variety and scale of projects is too diverse and include different demands of different parties.
Nevertheless, in this chapter we try to summarise the most important aspects of a project structure in the context of research.
We only tackle basic standards that help in every project.
We will not handle optional standards for specific research contexts.
Afterwards, we display reproducibility archives and the different requirements journals articulate for setting up an reproducibility archive.

## Basic standards for research projects

First of all, these basic standards are highly subjective.
As researchers in the discipline of psychology, our experience comes from psychological research projects.
Researchers from other disciplines might need to configure the project structure elements.
In psychology research, we assess these standards as highly useful:

1.  Human and machine-readable files
1.  `README.md`-file
1.  Separation of data and code
1.  `renv`-folder
1.  `misc`-folder

Apart from these standards, it is always useful to look for already existing standards in your research discipline.
Researchers working with fMRI data will find the convention of *Brain Images Data Structures ([BIDS]({{< var link.bids >}}))*.
BIDS is a standard that aims to foster a simple and easy way of organizing neuroimaging and behavioural data.
Inspired by BIDS, [*psych-DS*]({{< var link.psych-ds >}}) started in 2018 to aiming to provide a systematic way of formatting and documenting scientific datasets.
However, content creation by psych-DS has been low.
If you want to contribute to the project, take a look at their {{< fa brands github >}} Github [repository](https://github.com/psych-DS/psych-DS).

### Human and machine-readable files

As displayed in the chapter [Naming things](naming-things.qmd), human and machine-readable names for files and folders are relatively easy to modify, when starting a project.
As your project grows, you will be thankful for good file and folder names.
Since, we dedicated a whole chapter to this topic, we move on to the next basic standard of a project structure.

### `README.md`-file

A `README` is a text file that provides basic information about a project.
It is typically a Markdown (`.md`) file, which means you can use [Markdown]({{< var links.markdown >}}) syntax in it.
Markdown allows you to easily format text, create lists, include links, and embed images.
The exact content depends on your repository, but some general things that you might want to include are:

-   **Project description**: What function does this repository serve and what are it's key features?

-   **Installation instructions** (if applicable): Explain how to install and set up your project, including any dependencies or prerequisites.
    This is particularly relevant for repositories that contain programming code.
    Provide clear instructions to help users or contributors get started with your project quickly.

-   **Project structure**: Explain your project structure.
    Use one sentence to describe each file and folder.
    Examples are displayed [above](#examples).

-   **Usage** (if applicable): Provide examples or code snippets demonstrating how to use your project.

-   **Contributing**: If you welcome contributions, specify how others can contribute to your project.
    Here, you can also include guidelines for submitting bug reports, feature requests, or pull requests.

::: {.callout-tip collapse="true" appearance="simple"}
## Adding a `CONTRIBUTING.md` file to a repository

For larger or more complex projects where contributions may involve setting up a specific development environment or adhering to specific workflows, it is standard practice to create a file called `CONTRIBUTING.md`.
GitHub recognizes the presence of a `CONTRIBUTING.md` file in a repository and, for example, automatically includes a link to the `CONTRIBUTING.md` file when users open a new issue or pull request.
:::

-   **Acknowledgments**: Give credit to any third-party libraries, tools, or individuals that contributed to your project.

-   **License**: Choose a license that aligns with your project's goals.
    You can use [choosealicense.com](https://choosealicense.com) for guidance.
    The chosen license influences contributions to your project.
    Researchers are often insecure about which license to use.
    We will there cover the topic license in a separate chapter.

::: {.callout-tip collapse="true" appearance="simple" icon="true"}
## Find out more: View the `README.md` file of this project.

{{< include ../README.md >}}
:::

A `README.md`-file can include a lot of content.
When writing your `README`, consider your perspective as on-working researcher and other researchers that might want to reproduce parts of your project results.

### Separation of data and code

As seen in the [Examples](#examples), many researchers separate data and code in different folders.
It is also recommended to separate raw and clean (or tidy) data.
When conducting experiments in psychology, raw data usually do not come in a way that lets you start analysing the data.
Most (if not all) of the time, you need to configure the data.
These configurations should be based on code (rather than clicking in a graphical user interface).
The code that makes the raw data clean, should be included in the code folder of your project.
In R, a popular method for data cleaning is the use of the `tidyverse`, which we will cover in the chapter about good coding practices.

### `renv` folder

A `renv` folder helps you to create reproducible environments for your r projects.
`renv` saves and lists all your R-packages used in your project.
That means you have for each project an own project library in R.
When you are working in R to run your data analyses, you can create the `renv`-folder directly.
However, the use of `renv` is not intuitive, so we will cover the topic in another separate chapter.

### misc-folder

The abbreviation `misc` stands for miscellaneous.
This folder is particularly useful for files that do not fit into one of your other folders.
It saves you from having a chaotic project folder when entering your project.

## Structure of reproducibility archives

<!--#
> These are only comments.
> There is no aim of sufficiency and precision in the ideas below.

-   Different for each project and journal, when it comes to paper publishing
-   Show example of requirements of journal
-   Critically discuss if journal requirements are sufficient for computational reproducibility
-   Something's missing?


Below the line, the actual content starts
-->

In the first subsections of the chapter, you have learned how to set up your own project structure.
The structure is flexible to different occasions, e.g. working collaboratively with other team members, working at your own research project during your studies at university.
Nevertheless, you have not learned what is actually required by journals when you need or want to make your data and code publicly available.
To cover this topic, we will go into the details of open science requirements of a couple of journals.

### Requirements of Journals

The [TOP Guidelines](https://www.cos.io/initiatives/top-guidelines) by the Center of Open Science are a best practice formulation by journals, funders, and societies to implement better and more transparent research.
The [TOP Factor](https://topfactor.org) is a metric that reports the steps that a journal is taking to implement open science practices.
Below you can see the TOP Factor evaluation of two psychological journals.

::: {.callout-tip collapse="true"}
## Learn more: What is the TOP-Factor?

The TOP-FACTOR is a metric that assesses the open science policies of papers.
It considers different dimensions, such as *data transparency* and *materials transparency*.
In each dimension, a journal can achieve zero to three points.
A journal receives zero points in a dimension, when it is not implemented in the open science policy.
It receives three points in a dimension, when reproducibility of data and materials is not only required but also positively tested.
The sum score over all dimensions constitutes the TOP Factor.
The criteria for the scoring system is listed below:

|   | **NOT IMPLEMENTED** | **LEVEL I** | **LEVEL II** | **LEVEL III** |
|:--------------|:--------------|:--------------|:--------------|:--------------|
| **Data Citation** | No mention of data citation. | Journal describes citation of data in guidelines to authors with clear rules and examples. | Article provides appropriate citation for data and materials used consistent with journal's author guidelines. | Article is not published until providing appropriate citation for data and materials following journal's author guidelines. |
| **Data Transparency** | Journal encourages data sharing, or says nothing. | Article states whether data are available, and, if so, where to access them. | Data must be posted to a trusted repository. Exceptions must be identified at article submission. | Data must be posted to a trusted repository, and reported analyses will be reproduced independently prior to publication. |
| **Analysis Code Transparency** | Journal encourages code sharing, or says nothing. | Article states whether code is available, and, if so, where to access it. | Code must be posted to a trusted repository. Exceptions must be identified at article submission. | Code must be posted to a trusted repository, and reported analyses will be reproduced independently prior to publication. |
| **Materials Transparency** | Journal encourages materials sharing, or says nothing. | Article states whether materials are available, and, if so, where to access them. | Materials must be posted to a trusted repository. Exceptions must be identified at article submission. | Materials must be posted to a trusted repository, and reported analyses will be reproduced independently prior to publication. |
| **Design & Analysis Reporting Guidelines** | Journal encourages design and analysis transparency, or says nothing. | Journal articulates design transparency standards. | Journal requires adherence to design transparency standards for review and publication. | Journal requires and enforces adherence to design transparency standards for review and publication. |
| **Study Preregistration** | Journal says nothing. | Article states whether preregistration of study exists, and, if so, where to access it. | Article states whether preregistration of study exists, and, if so, allows journal access during peer review for verification. | Journal requires preregistration of studies and provides link and badge in article to meeting requirements. |
| **Analysis Plan Preregistration** | Journal says nothing. | Article states whether preregistration of study exists, and, if so, where to access it. | Article states whether preregistration with analysis plan exists, and, if so, allows journal access during peer review for verification. | Journal requires preregistration of studies with analysis plans and provides link and badge in article to meeting requirements. |
| **Replication** | Journal discourages submission of replication studies, or says nothing. | Journal encourages submission of replication studies. | Journal encourages submission of replication studies and conducts results blind review. | Journal uses Registered Reports as a submission option for replication studies with peer review prior to observing the study outcomes. |

TOP Guidelines [Summary Table](https://topfactor.org/summary).
License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
Used without any modifications.
:::

::: panel-tabset
## Frontiers

TOP-Factor assessment of *Frontiers in Psychology*

| **GUIDELINE** | **LEVEL** | **SUMMARY** | **JUSTIFICATION** |
|:-----------------|:-----------------|:-----------------|:-----------------|
| **Total** | **13** |  |  |
| Data Citation | **1** | Journal describes citation of data in guidelines to authors with clear rules and examples. | "Authors are encouraged to cite all datasets generated or analyzed in the study. " Includes example. |
| Data Transparency | **2** | Data must be posted to a trusted repository. Exceptions must be identified at article submission. | "Frontiers is committed to open science and open data; we require that authors make available all data relevant to the conclusions of the manuscript." |
| Analysis Code Transparency | **2** | Code must be posted to a trusted repository. Exceptions must be identified at article submission. | "Frontiers is committed to open science and open data; we require that authors make available all code used to conduct their research available to other researchers. " |
| Materials Transparency | **2** | Materials must be posted to a trusted repository. Exceptions must be identified at article submission. | "Authors are required to make all materials used to conduct their research available to other researchers." |
| Design & Analysis Reporting Guidelines | **0** | Journal encourages design and analysis transparency, or says nothing. | No mention. |
| Study Preregistration | **0** | Journal says nothing. | No mention. |
| Analysis Plan Preregistration | **0** | Journal says nothing. | No mention. |
| Replication | **3** | Journal uses Registered Reports as a submission option for replication studies with peer review prior to observing the study outcomes. | Journal accepts Registered Reports. |
| Registered Reports & Publication Bias | **3** |  | Journal accepts Registered Reports. |
| Open Science Badges | **0** |  | No mention. |

Open access policy of Frontiers in Psychology summarised by [TOP Factor](https://topfactor.org/journals/frontiers-in-psychology-2).
License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
Used without any modifications.

## AMPPS

TOP-Factor assessment of *Advances in Methods and Practices in Psychological Science*

| **GUIDELINE** | **LEVEL** | **SUMMARY** | **JUSTIFICATION** |
|:-----------------|:-----------------|:-----------------|:-----------------|
| **Total** | **25** |  |  |
| Data Citation | **2** | Article provides appropriate citation for data and materials used consistent with journal's author guidelines. | Journal requires data citation. |
| Data Transparency | **2** | Data must be posted to a trusted repository. Exceptions must be identified at article submission. | Journal requires data sharing. |
| Analysis Code Transparency | **2** | Code must be posted to a trusted repository. Exceptions must be identified at article submission. | Journal requires code sharing. |
| Materials Transparency | **2** | Materials must be posted to a trusted repository. Exceptions must be identified at article submission. | Journal requires materials sharing. |
| Design & Analysis Reporting Guidelines | **3** | Journal requires and enforces adherence to design transparency standards for review and publication. | Adherence to reporting guidelines is enforced. |
| Study Preregistration | **3** | Journal requires preregistration of studies and provides link and badge in article to meeting requirements. | Preregistration is required. |
| Analysis Plan Preregistration | **3** | Journal requires preregistration of studies with analysis plans and provides link and badge in article to meeting requirements. | Analysis plan preregistration is required. |
| Replication | **3** | Journal uses Registered Reports as a submission option for replication studies with peer review prior to observing the study outcomes. | Journal accepts Registered Reports for replication studies. |
| Registered Reports & Publication Bias | **3** |  | Journal accepts Registered Reports for novel studies. |
| Open Science Badges | **2** |  | Journal offers all Open Science Badges. |
:::

As you can see, journals do include requirements of public data and code for publishing articles.
However, the specification of *how* to do that is scarce.
Standards for research projects as stated above are missing.
We further look at some examples of the application of open data and code policies in published articles.

### Current application of open science practices

::: panel-tabset
## Frontiers

```{r}
#| results: asis
#| eval: true
#| echo: false

#insert frontiers screenshot /first merge naming things
#cat(make_images("frontiers-paper"))

#insert to _images.yml-file
#frontiers-paper:
  #title: "Exploring self-regulation theory as a mechanism of the effects of psychological contract fulfillment: The role of emotional intelligence"
  #authors: "Lyonel Laulié, Gabriel Briceño-Jiménez, Gisselle Henríquez-Gómez"
  #author-url: "https://movil.fen.uchile.cl/es/academicos-investigacion/directorio-de-academicos/detalle/lyonel-laulie"
  #image-file: "frontiers-paper-screenshot.png"
  #image-url: "https://osf.io/ufq9g"
  #license: "CC-BY"
  #license-url: "https://creativecommons.org/licenses/by/4.0/"
  #license-reference: ""
  #comments: "reused without modifications"
  #alt-text: ""
```

Below, you can find the structure of the reproducibility archive of a paper from @laulie2023.
The paper is placed in work and organizational psychology and postulates a relationship between the fulfillment of (implicit) expectation between employees and employers and the intention to leave the company for another job.
The authors further assume that this relationship is mediated by emotional exhaustion and investigate whether emotional intelligence moderates the mediation effect of emotional exhaustion.

```{zsh filename="Output"}
├── fpsyg-14-1090094.pdf                
├── Materials - DataBase.xlsx           
├── Materials - Informed Consent.pdf    
├── Materials - Instruments.pdf         
```

Here, you can find the link to the archive of the paper: [Reproducibility Archive](https://osf.io/csdk8/?view_only=)

## AMPPS

```{r}
#| results: asis
#| eval: true
#| echo: false

#insert ampps screenshot /first merge naming things
#cat(make_images("ampps-paper"))

#insert to _images.yml-file
#ampps-paper:
  #title: "Implementing Statcheck During Peer Review Is Related to a Steep Decline in Statistical-Reporting Inconsistencies"
  #authors: "Michèle B. Nuijten and Jelte M. Wicherts"
  #author-url: "https://orcid.org/0000-0002-1468-8585"
  #image-file: "ampps-paper-screenshot.png"
  #image-url: "https://journals.sagepub.com/doi/epdf/10.1177/25152459241258945"
  #license: "CC-BY 4.0"
  #license-url: "https://creativecommons.org/licenses/by/4.0/"
  #license-reference: ""
  #comments: "reused without modifications"
  #alt-text: ""
```

Below you can find the structure of an archive of a paper from @nuijten2024.
The paper is placed in the methodological area of psychological science.
The authors investigated whether inconsistencies in reporting statistical results could be reduced by implementing a software tool called *statcheck*.

::: {.callout-note title="Structure of the Repro Archive from @nuijten2024" collapse="true"}
## File descriptions {.unnumbered}
The file descriptions below are organized in the same way as the components and folders on the OSF page at [https://osf.io/q84jn/](https://osf.io/q84jn/).

### 02 Preregistration {.unnumbered}
| File Name | Description | Created By |
|:--|:--|:--|
|221130preregistration_effectivitystatcheck.pdf|Preregistration of the project|MN, JW|

#### Power analysis {.unnumbered}
| File Name | Description | Created By |
|:--|:--|:--|
| 00extract_dates.R              | Helper function with regexes to extract dates                         | MN         |
| 00extract_pattern.R            | Helper function to extract a pattern from text                        | MN         |
| 00html_to_txt.R                | Helper function to convert html files to plain txt                    | MN         |
| 00scrape_html_dir.R            | Helper function that allows scraping a directory of html files        | MN         |
| 01scrape_articles.R            | Function to run statcheck & scrape additional meta-data from articles | MN         |
| 02data_wrangling.R             | Function to clean & reorder raw data                                  | MN         |
| 2022-11-23scraped_articles.txt | Raw, scraped data from articles                                       | MN         |
| 2022-11-28data_per_article.txt | Data organized at article level                                       | MN         |
| 2022-11-28data_wrangled.txt    | Data with additional variables and missing values removed             | MN         |
| power_analysis.R               | R script to run power simulation                                      | MN         |
| powerplot_estimated.png        | Graph of power estimates per b3 value                                 | MN         |

### 03 Data {.unnumbered}
| File Name | Description| Created By |
|:--|:--|:--|
| 00extract_dates_v2.R   | Helper function with regexes to extract dates                         | MN         |
| 00extract_pattern.R | Helper function to extract a pattern from text                        | MN         |
| 00html_to_txt_v2.R     | Helper function to convert html files to plain txt                    | MN         |
| 00scrape_html_dir.R | Helper function that allows scraping a directory of html files        | MN         |
| 01scrape_articles_v3.R | Function to run statcheck & scrape additional meta-data from articles | MN         |
| 02data_wrangling_v3.R  | Function to clean & reorder raw data                                  | MN         |
|2024-04-15scraped_articles_v3.txt|Raw statcheck data|MN|
|2024-04-15data_per_article_with_missings.txt|Data organized per article, including articles without NHST results|MN|
|2024-04-15data_per_article_with_stats.txt|Data organized per article, only including articles with NHST results|MN|
|2024-04-15data_wrangled_no_missings.txt|Clean data organized per NHST result, only including articles with NHST results|MN|
|2024-04-15data_wrangled_with_missings.txt|Clean data organized per NHST result, also including articles without NHST results (in these cases, only article level info is in the data frame)|MN|
|missing_htmls_jepg.docx/-.pdf|List of articles from JEPG with missing html file|MN|
|codebook.xlsx|Codebook explaining the variables in the main data files|MN|

### 04 Analysis {.unnumbered}

#### 01 Descriptives {.unnumbered}

| File Name | Description| Created By |
|:--|:--|:--|
|descriptives_V3.R|Main analysis file to create descriptive statistics, figures, and tables | MN |
|fig1_violin_plots.png|Figure 1|MN|
|fig2_line_graph_means.png|Figure 2|MN|
|table2.txt|Raw data from Table 2|MN|
|table3.txt|Raw data from Table 3|MN|

#### 02 Confirmatory {.unnumbered}

| File Name | Description| Created By |
|:--|:--|:--|
|confirmatory_analyses_v3.R|Main analysis script for confirmatory analyses|MN|
|illustration_logits_odds_probs.xlsx|Toy example to convert obtained regression coefficients from logits to probabilities|MN|
|lm_dec_errors.rda|R data object with output of the multilevel logistic model estimating the probability of a decision error|MN|
|lm_errors.rda|R data object with output of the multilevel logistic model estimating the probability of an error|MN|

#### 03 Exploratory {.unnumbered}

| File Name | Description| Created By |
|:--|:--|:--|
|bayes_factors.R|Calculating Bayes factors and posterior probabilities|MN|
|fig3_perc_articles_errors_over_time.png|Figure 3|MN|
|separate_journal_pairs.R|Fit regression models for journal pairs separately|MN|
|trends_over_time.R|Calculate and visualize trends over time|MN|

### renv {.unnumbered}

| File Name | Description| Created By |
|:--|:--|:--|
|renv (folder), .Rprofile, renv.lock|Files for syncing the same R package versions used in the data analysis|MN|

:::


Here you can fend the link to archive of the paper: [Reproducibility Archive](https://osf.io/q84jn/)

:::

::: callout-caution
## Exercise: Study reproducibility archives

Investigate the reproducibility archives above and think about how these archives could help you to reproduce the analysis conducted in their papers.
What is helpful and what is not?
:::

::: {.callout-note title="Postscript"}
The examples from @laulie2023 and @nuijten2024 do not have the intention to discredit researchers.
Rather, the paper were chosen from the respective journal websites on a random basis.
:::

Again, it should be noted that there is no perfectly organized reproducibility archive.
However, we hope that the displayed examples show that open science, open data and reproducibility can be applied in many different ways.
