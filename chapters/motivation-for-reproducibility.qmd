---
title: "Motivation for reproducible science"
engine: knitr
execute:
  eval: false
  warning: false
  message: false
categories: [beginner, basics]
abstract: |
  In this chapter, you learn about typical arguments in the Open Science debate.
  You will learn why some people do or do not engage in a reproducible workflow.
---

Reproducibility is a big topic, we spent a lot of work and time in writing a book about it and you will probably spend a lot time learning about it.
If you are asking the question "What for? Why should I do reproducible research?", that's completely reasonable.
We decided to dedicate a whole chapter to this question, because it is very important to us describing different facets of the topic reproducibility.
Most of the arguments we will point out is not restricted to reproducibility but covers the whole topic of open science.

## Reproducibility: Simple and unnecessary?

After the definition of reproducibility in the previous chapter, you might have one of two thoughts: Either you think, that getting the same results from the same data and code has to be common practice and super simple.
Just to ruin your day, you can search for a paper with public code and data and try to reproduce the results from the article.
While you are doing this (or wisely not) you may also start to figure out that many problems can occur when trying to reproduce scientific results.
The amount of time spending on making your research reproducible and eventually prepare solutions for many different problems that can occur, can give you a headache.
Or you think that your time spending on making your research reproducible is simply not worth it.
When you want to succeed as a researcher (PhD, Post-doc) and get a professorship at a university you need to get published in journals with high impact factors, significant results to get published in such journals and receive a lot of citations from other researchers (see @nte-abele-brehm2016).
Where is the time for reproducibility?
Isn't the reward system of science directly against good research practices?
If you do not publish your code you can (un)intentionally and undetectedly make code errors that might confirm your hypthesized results.
You can selectively report outcomes that confirm your hypotheses and climb the career ladder.
Making your research reproducible and spend time with this learning resource is not valuable for your research career.

::: {#nte-abele-brehm2016 title="Evaluation of selection criteria in appointment procedures in psychology" .callout-note collapse="false"}
In a study by @abele-brehm2016, about 1,450 researchers in Psychology (members of the German Psychological Association) answered an online questionnaire, in which they rated the desired relevance of 41 selection criteria as well as their actual relevance in hiring procedures in psychology (66% of the respondents were actually members of a professorship hiring committee at least once).
While some qualitative indicators like the fit of research profile to the appointing institute (Rank 2) and the quality of the research presentation (Rank 3)" were also deemed relevant, several of the actually relevant indicators were quantitative and considered the number of peer-reviewed publications (Rank 1), the number of publications (Rank 4), the volume of third-party funding acquired to date (Rank 5) as well as the number of first-author publications (Rank 6).
Also notably, "indicators of research transparency" took the *last* rank of 41 selection criteria.
:::

::: {.callout-warning title="Arguments against Open Science practices}
- time consuming
- not important for climbing the career-ladder
- possible data misuse of shared data
- against innovation-driven research
- against business model of private research companies
:::

But there is also a different narrative:

## Reproducibility: Hard and worth-it

> Goodhart's Law: When a measure becomes a target, it ceases to be a good measure.
> @goodhart1984

```{r}
#| results: asis
#| eval: true
#| echo: false
#| warning: false
cat(make_figure("xkcd-goodharts-law"))
```

Lets take another perspective.
First of all, ask yourself: What is your primary goal as a researcher?
Is it climbing the career ladder by publishing in high impact factor journals or conducting high quality research or something else?
The focus on those measures like *Impact-Factors* and *h*-indexes.
Does one of that exclude the other?
Why do you think so?
In a highly-debated [blog post](https://talyarkoni.org/blog/2018/10/02/no-its-not-the-incentives-its-you/), Tal Yarkoni stated that as researchers, we are not helpless prisoners in the reward system of science.
We are an active part of our respective scientific community.
We have the ability to shape our work and craft our jobs in the direction of reproducibility (which can also improve mental well-being and job performance [@bakker2023]).
No matter what, we have to take responsibility for out actions, if we want to or not, and we cannot blame the incentives of science and lose our responsibility for our work.

However, there are some arguments by @mckiernan2016 that open science practices (e.g. reproducible data and code) can even enhance your visibility as a researcher and give yourself a headstart at the academic market.
When you publish your code and data of your published articles, others can work with your data.
They may rerun your analysis, try to answer different research questions with your data or apply new methods on your data.
Especially the conduction of meta-analyses is simplified if your data and code is available and reproducible.
By that would you get more citations in comparison to the case where you do not make your code and data publicly available.
And further you are cited in important review-articles which also increases your visibility as researcher.
You can also benefit the other way around.
If there is a data set or calculation that suits your research question, you can use open data sets and saving a lot of time for data acquisition.

But how do you convince your supervisor to give you the time to make your research reproducible?
Supervisors need the research and jobs to be funded by different organisations (as the [Horizon Europe](https://commission.europa.eu/funding-tenders/find-funding/eu-funding-programmes/horizon-europe_en?prefLang=de) funding pool from the European Commission).
These organisations require now open access practices including a call for reproducible research (for Horizon Europe see [here](https://research-and-innovation.ec.europa.eu/document/download/e69aff11-4494-4e5f-866c-694539a3ea26_en?filename=ec_rtd_commitments-reform-research-assessment.pdf) and [here](https://erc.europa.eu/manage-your-project/open-science)).
That means your supervisor would lose funding opportunities, if they don't engage with you in open science practices and reproducible research.

## Reproducibility pays off in the long run

During this book, you will learn about project management, folder structure, version control, docker environments, coding practices and more.
At first, all these tools intend to improve your reproducibility but may slow down your current research process.
In the long run, you will save a lot of time once you get used to the proposed working process.
Maybe you can remember your first research project during your undergraduate program.
Do you still have access to it?
Can you reproduce, what you have done there?
Do you even understand what you have done there?
In your research career (and also outside of research) you will have to deal with much larger projects.
It is of great importance to keep your projects as tidy as possible - for your colleagues and collaborators and for future you.

## Extent of reproducibility

As you will learn throughout this book, reproducibility is not a binary construct. 
There is no checklist waiting for you to tick off the open bullet points. 
Its not that you either do or don't do reproducible research. 
You can think of reproducibility more as a scale (see @fig-repro-scale) and you are shifting your reproducibility upwards by applying the tools you learn in this online resource. 

```{r}
#| results: asis
#| eval: true
#| echo: false
#| warning: false
#| label: fig-repro-scale
cat(make_figure("repro-scale"))
```

So let's get started to **improve your reproducibility**:

## Resources

If you want to dive deeper in the discussion of the value of reproducibility and open science and how to change behavior, here are some resources:

-   <https://talyarkoni.org/blog/2018/10/02/no-its-not-the-incentives-its-you/>

-   <https://www.sciencedirect.com/science/article/pii/S0896627318310390>

-   <https://erc.europa.eu/manage-your-project/open-science>

-   <https://topfactor.org/>

-   <https://elifesciences.org/articles/16800>

-   <https://osf.io/652qw>
